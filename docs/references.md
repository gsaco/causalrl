# References

## Off-policy evaluation

- Precup, D. (2000). Eligibility Traces for Off-Policy Policy Evaluation. PhD thesis, University of Massachusetts Amherst.
- Mahmood, A. R., Yu, H., Sutton, R. S., and Szepesvari, C. (2014). Weighted Importance Sampling for Off-Policy Learning with Linear Function Approximation. NeurIPS.
- Jiang, N. and Li, L. (2016). Doubly Robust Off-Policy Value Evaluation for Reinforcement Learning. ICML.
- Thomas, P. S. and Brunskill, E. (2016). Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning. ICML.
- Hao, B., Ji, X., Duan, Y., Lu, H., Szepesvari, C., and Wang, M. (2021). Bootstrapping Statistical Inference for Off-Policy Evaluation. arXiv.
- Zhang, R., Zhang, X., Ni, C., and Wang, M. (2022). Off-Policy Fitted Q-Evaluation with Differentiable Function Approximators: Z-Estimation and Inference Theory. ICML.

## Causal RL overview

- Deng, Y., Jiang, N., Long, J., and Zhang, C. (2023). Causal Reinforcement Learning: A Survey. arXiv:2307.01452.

## Sequential ignorability

- Robins, J. M., Hernan, M. A., and Brumback, B. (2000). Marginal Structural Models and Causal Inference in Epidemiology. Epidemiology.
