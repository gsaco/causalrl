{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a3852e",
   "metadata": {},
   "source": [
    "# 08 — Estimator Selection and Debugging\n",
    "\n",
    "We show a diagnostics-driven estimator selection workflow and a debugging\n",
    "checklist when overlap or model fit is poor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393dbce",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "```\n",
    "pip install \"causalrl[plots]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e565db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from crl.assumptions import AssumptionSet\n",
    "from crl.assumptions_catalog import MARKOV, OVERLAP, SEQUENTIAL_IGNORABILITY\n",
    "from crl.benchmarks.mdp_synth import SyntheticMDP, SyntheticMDPConfig\n",
    "from crl.estimands.policy_value import PolicyValueEstimand\n",
    "from crl.selectors import select_estimator\n",
    "from crl.utils.seeding import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5faa2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb77f36",
   "metadata": {},
   "source": [
    "## Run selection\n",
    "\n",
    "We use a heuristic score that favors stable importance weights and reasonable\n",
    "model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a96b547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsaco/Documents/GitHub/causalrl/crl/estimators/wdr.py:150: UserWarning: 'where' used without 'out', expect unitialized memory in output. If this is intentional, use out=None.\n",
      "  weights_norm = np.divide(weights, weights_sum, where=weights_sum > 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ISEstimator(run_diagnostics=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = SyntheticMDP(SyntheticMDPConfig(seed=0, horizon=5))\n",
    "dataset = benchmark.sample(num_trajectories=200, seed=1)\n",
    "\n",
    "estimand = PolicyValueEstimand(\n",
    "    policy=benchmark.target_policy,\n",
    "    discount=dataset.discount,\n",
    "    horizon=dataset.horizon,\n",
    "    assumptions=AssumptionSet([SEQUENTIAL_IGNORABILITY, OVERLAP, MARKOV]),\n",
    ")\n",
    "\n",
    "best = select_estimator(\n",
    "    dataset,\n",
    "    estimand,\n",
    "    candidates=[\"is\", \"wis\", \"pdis\", \"dr\", \"wdr\", \"mrdr\", \"fqe\"],\n",
    ")\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea4113b",
   "metadata": {},
   "source": [
    "## Debug playbook\n",
    "\n",
    "- **Overlap bad** → inspect ESS and weight tails, consider WIS/DR, or collect\n",
    "  more coverage.\n",
    "- **Model fit bad** → check Q-model MSE, increase model capacity, or switch to\n",
    "  IS-based estimators.\n",
    "- **Propensities unknown** → estimate behavior policy or use model-based OPE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78d178",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "- Estimator selection is heuristic, but diagnostics make it principled.\n",
    "- Always triangulate with multiple estimators and failure-mode checks."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
